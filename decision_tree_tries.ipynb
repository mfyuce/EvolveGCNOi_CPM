{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e669c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: [0 1 2 3 4 5 6 7 8 9]\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.998528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22837\n",
      "[LightGBM] [Info] Number of data points in the train set: 15915263, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -1.774311\n",
      "[LightGBM] [Info] Start training from score -6.903321\n",
      "[LightGBM] [Info] Start training from score -8.009027\n",
      "[LightGBM] [Info] Start training from score -2.219580\n",
      "[LightGBM] [Info] Start training from score -1.833900\n",
      "[LightGBM] [Info] Start training from score -2.193644\n",
      "[LightGBM] [Info] Start training from score -2.086688\n",
      "[LightGBM] [Info] Start training from score -2.096901\n",
      "[LightGBM] [Info] Start training from score -2.391472\n",
      "[LightGBM] [Info] Start training from score -2.201109\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 1.60059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.62      0.52   1156814\n",
      "           1       0.38      0.40      0.39      6851\n",
      "           2       0.27      0.28      0.28      2268\n",
      "           3       0.39      0.57      0.46    741116\n",
      "           4       0.43      0.67      0.52   1089894\n",
      "           5       0.44      0.30      0.36    760588\n",
      "           6       0.48      0.45      0.46    846447\n",
      "           7       0.48      0.34      0.40    837847\n",
      "           8       0.60      0.25      0.35    624071\n",
      "           9       0.63      0.19      0.29    754932\n",
      "\n",
      "    accuracy                           0.45   6820828\n",
      "   macro avg       0.45      0.41      0.40   6820828\n",
      "weighted avg       0.48      0.45      0.43   6820828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Convert object columns to categorical\n",
    "for col in df.select_dtypes(include=\"object\"):\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Show class labels\n",
    "print(\"Unique classes:\", y.unique())\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Set up LightGBM model for multiclass\n",
    "num_classes = y.nunique()\n",
    "\n",
    "model = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=num_classes,\n",
    "    max_depth=10,\n",
    "    n_estimators=1000\n",
    ")\n",
    "\n",
    "# Fit with early stopping callback\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=\"multi_logloss\",\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=10)],\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd2739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.60      0.41   1156814\n",
      "           1       0.89      0.98      0.93      6851\n",
      "           2       0.99      1.00      0.99      2268\n",
      "           3       0.61      0.81      0.69    741116\n",
      "           4       0.31      0.57      0.40   1089894\n",
      "           5       0.28      0.15      0.19    760588\n",
      "           6       0.33      0.15      0.21    846447\n",
      "           7       0.30      0.29      0.29    837847\n",
      "           8       0.43      0.00      0.00    624071\n",
      "           9       0.30      0.02      0.03    754932\n",
      "\n",
      "    accuracy                           0.35   6820828\n",
      "   macro avg       0.48      0.46      0.42   6820828\n",
      "weighted avg       0.35      0.35      0.30   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.2542\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Split features and label\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "# Define preprocessing (one-hot encode categorical features)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)],\n",
    "    remainder=\"passthrough\"  # numeric columns stay as is\n",
    ")\n",
    "\n",
    "# Create LinearSVC pipeline\n",
    "svm_model = make_pipeline(\n",
    "    preprocessor,\n",
    "    LinearSVC(max_iter=10000, dual=False)  # dual=False is faster for large dense datasets\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Fit\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0940cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "from scipy.stats import mode\n",
    "import faiss\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Feature / label split\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(\"missing\")\n",
    "X[num_cols] = X[num_cols].fillna(0)\n",
    "\n",
    "# Hash categorical features to sparse matrix\n",
    "X_cat_dicts = X[cat_cols].astype(str).to_dict(orient=\"records\")\n",
    "hasher = FeatureHasher(n_features=1024, input_type='dict')\n",
    "X_cat_hashed_sparse = hasher.transform(X_cat_dicts)\n",
    "\n",
    "# Scale numerical features\n",
    "X_num_scaled = StandardScaler().fit_transform(X[num_cols]).astype(\"float32\")\n",
    "X_num_sparse = sparse.csr_matrix(X_num_scaled)\n",
    "\n",
    "# Combine features\n",
    "X_combined_sparse = hstack([X_cat_hashed_sparse, X_num_sparse]).tocsr()\n",
    "\n",
    "# Print estimated memory if made dense\n",
    "approx_gb = X_combined_sparse.shape[0] * X_combined_sparse.shape[1] * 4 / 1024**3\n",
    "print(f\"Estimated size if dense: {approx_gb:.2f} GB\")\n",
    "\n",
    "# Reduce dimensions to a manageable size\n",
    "svd = TruncatedSVD(n_components=128, random_state=42)\n",
    "X_reduced = svd.fit_transform(X_combined_sparse).astype(\"float32\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reduced, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# FAISS\n",
    "d = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(X_train)\n",
    "\n",
    "# Search\n",
    "k = 5\n",
    "_, indices = index.search(X_test, k)\n",
    "\n",
    "# Predict\n",
    "y_pred = mode(y_train.to_numpy()[indices], axis=1).mode.flatten()\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"MCC:\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebaa4e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.49      0.59   1156814\n",
      "           1       0.33      0.98      0.50      6851\n",
      "           2       1.00      1.00      1.00      2268\n",
      "           3       0.29      0.93      0.44    741116\n",
      "           4       0.64      0.57      0.60   1089894\n",
      "           5       0.53      0.51      0.52    760588\n",
      "           6       0.64      0.48      0.55    846447\n",
      "           7       0.77      0.36      0.49    837847\n",
      "           8       0.58      0.52      0.55    624071\n",
      "           9       0.71      0.33      0.45    754932\n",
      "\n",
      "    accuracy                           0.52   6820828\n",
      "   macro avg       0.62      0.62      0.57   6820828\n",
      "weighted avg       0.62      0.52      0.53   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.4742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", make_pipeline(\n",
    "            SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "            OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        ), cat_cols),\n",
    "        (\"num\", SimpleImputer(strategy=\"mean\"), num_cols)\n",
    "    ]\n",
    ") \n",
    "\n",
    "# Random Forest model pipeline\n",
    "rf_model = make_pipeline(\n",
    "    preprocessor,\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100,           # Increase for better accuracy, decrease for speed\n",
    "        max_depth=20,               # Set to None for full growth\n",
    "        n_jobs=-1,                  # Use all CPU cores\n",
    "        class_weight=\"balanced\",   # Useful for imbalanced classes\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2df0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep                  float64\n",
      "cpm_id                   category\n",
      "vehicle_id               category\n",
      "detected_vehicle_id      category\n",
      "object_type              category\n",
      "detected_object_type     category\n",
      "label_detected              int64\n",
      "x_detected                float64\n",
      "y_detected                float64\n",
      "speed_detected            float64\n",
      "heading_detected          float64\n",
      "acceleration_detected     float64\n",
      "is_self                     int64\n",
      "sensor_id                category\n",
      "sensor_type              category\n",
      "sensor_range                int64\n",
      "weather_conditions       category\n",
      "visibility_range            int64\n",
      "detection_confidence      float64\n",
      "dtype: object\n",
      "timestep                 0\n",
      "cpm_id                   0\n",
      "vehicle_id               0\n",
      "detected_vehicle_id      0\n",
      "object_type              0\n",
      "detected_object_type     0\n",
      "label_detected           0\n",
      "x_detected               0\n",
      "y_detected               0\n",
      "speed_detected           0\n",
      "heading_detected         0\n",
      "acceleration_detected    0\n",
      "is_self                  0\n",
      "sensor_id                0\n",
      "sensor_type              0\n",
      "sensor_range             0\n",
      "weather_conditions       0\n",
      "visibility_range         0\n",
      "detection_confidence     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'CPM_truck43_586.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m HistGradientBoostingClassifier(\n\u001b[1;32m     33\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     34\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m     44\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:361\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# time spent predicting X for gradient and hessians update\u001b[39;00m\n\u001b[1;32m    360\u001b[0m acc_prediction_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 361\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_DTYPE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_y(y)\n\u001b[1;32m    363\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/core/generic.py:1993\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: NpDtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 1993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'CPM_truck43_586.0'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# ‚ùó Convert all object columns to pandas 'category' dtype BEFORE train-test split\n",
    "for col in X.select_dtypes(include=\"object\").columns:\n",
    "    X[col] = X[col].astype(\"category\")\n",
    "assert not any(X.dtypes == \"object\"), \"Object columns remain!\"\n",
    "\n",
    "print(X.dtypes) \n",
    "\n",
    "# Fill missing in categorical columns with a special label\n",
    "for col in X.select_dtypes(include=\"category\").columns:\n",
    "    X[col] = X[col].cat.add_categories([\"__missing__\"]).fillna(\"__missing__\")\n",
    "\n",
    "print(X.isna().sum())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Define model\n",
    "model = HistGradientBoostingClassifier(\n",
    "    max_iter=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Final dtypes before training:\\n\", X_train.dtypes)\n",
    "print(\"Sample row:\\n\", X_train.head(1).to_dict())\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeee3889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.00      0.00   1156814\n",
      "           1       0.09      0.69      0.16      6851\n",
      "           2       0.13      0.95      0.23      2268\n",
      "           3       0.26      0.42      0.32    741116\n",
      "           4       0.54      0.04      0.08   1089894\n",
      "           5       0.34      0.03      0.06    760588\n",
      "           6       0.52      0.03      0.06    846447\n",
      "           7       0.43      0.03      0.06    837847\n",
      "           8       0.11      0.87      0.19    624071\n",
      "           9       0.27      0.05      0.09    754932\n",
      "\n",
      "    accuracy                           0.15   6820828\n",
      "   macro avg       0.31      0.31      0.12   6820828\n",
      "weighted avg       0.39      0.15      0.09   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.0914\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Split features and label\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "# Define preprocessing (OneHotEncoding)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Create SGDClassifier pipeline\n",
    "sgd_model = make_pipeline(\n",
    "    preprocessor,\n",
    "    SGDClassifier(\n",
    "        loss=\"hinge\",        # Linear SVM\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        class_weight=\"balanced\",  # optional if class imbalance\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fit\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8f009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1156814\n",
      "           1       0.35      1.00      0.52      6851\n",
      "           2       0.91      1.00      0.95      2268\n",
      "           3       1.00      1.00      1.00    741116\n",
      "           4       1.00      1.00      1.00   1089894\n",
      "           5       1.00      1.00      1.00    760588\n",
      "           6       1.00      1.00      1.00    846447\n",
      "           7       1.00      1.00      1.00    837847\n",
      "           8       1.00      1.00      1.00    624071\n",
      "           9       1.00      1.00      1.00    754932\n",
      "\n",
      "    accuracy                           1.00   6820828\n",
      "   macro avg       0.93      1.00      0.95   6820828\n",
      "weighted avg       1.00      1.00      1.00   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.9977\n"
     ]
    }
   ],
   "source": [
    "#RidgeClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "# Preprocessing with OneHotEncoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# RidgeClassifier pipeline\n",
    "ridge_model = make_pipeline(\n",
    "    preprocessor,\n",
    "    RidgeClassifier(\n",
    "        alpha=1.0,\n",
    "        class_weight=\"balanced\",  # good for imbalanced classes\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb60683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1156814\n",
      "           1       0.34      0.98      0.51      6851\n",
      "           2       0.27      1.00      0.43      2268\n",
      "           3       1.00      1.00      1.00    741116\n",
      "           4       1.00      1.00      1.00   1089894\n",
      "           5       1.00      1.00      1.00    760588\n",
      "           6       1.00      1.00      1.00    846447\n",
      "           7       1.00      1.00      1.00    837847\n",
      "           8       1.00      1.00      1.00    624071\n",
      "           9       1.00      1.00      1.00    754932\n",
      "\n",
      "    accuracy                           1.00   6820828\n",
      "   macro avg       0.86      1.00      0.89   6820828\n",
      "weighted avg       1.00      1.00      1.00   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.9964\n"
     ]
    }
   ],
   "source": [
    "#RidgeClassifier - No Node Id\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Split features and target\n",
    "# timestep,cpm_id,vehicle_id,detected_vehicle_id,object_type,detected_object_type,cls_detected,label_detected,x_detected,y_detected,speed_detected,heading_detected,acceleration_detected,is_self,sensor_id,sensor_type,sensor_range,weather_conditions,visibility_range,detection_confidence\n",
    "X = df.drop([\"cls_detected\",\"vehicle_id\",\"detected_vehicle_id\"], axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "# Preprocessing with OneHotEncoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# RidgeClassifier pipeline\n",
    "ridge_model = make_pipeline(\n",
    "    preprocessor,\n",
    "    RidgeClassifier(\n",
    "        alpha=1.0,\n",
    "        class_weight=\"balanced\",  # good for imbalanced classes\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e462b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [05:56:20] WARNING: /croot/xgboost-split_1749630910898/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.72      0.58   1156814\n",
      "           1       0.82      0.93      0.87      6851\n",
      "           2       1.00      0.99      1.00      2268\n",
      "           3       0.41      0.65      0.50    741116\n",
      "           4       0.41      0.76      0.53   1089894\n",
      "           5       0.61      0.24      0.35    760588\n",
      "           6       0.55      0.47      0.51    846447\n",
      "           7       0.61      0.34      0.44    837847\n",
      "           8       0.69      0.24      0.36    624071\n",
      "           9       0.70      0.19      0.29    754932\n",
      "\n",
      "    accuracy                           0.48   6820828\n",
      "   macro avg       0.63      0.55      0.54   6820828\n",
      "weighted avg       0.55      0.48      0.46   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.4115\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Categorical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "# Preprocessing: OneHotEncode categoricals\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# XGBoost classifier pipeline\n",
    "xgb_model = make_pipeline(\n",
    "    preprocessor,\n",
    "    XGBClassifier(\n",
    "        objective=\"multi:softmax\",         # or \"multi:softprob\" if you want probabilities\n",
    "        num_class=len(y.unique()),\n",
    "        eval_metric=\"mlogloss\",\n",
    "        max_depth=10,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        use_label_encoder=False,\n",
    "        tree_method=\"hist\",                # use \"gpu_hist\" if running on GPU\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8a0d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Detect categorical columns (CatBoost accepts column names or indices)\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "X[cat_cols] = X[cat_cols].fillna(\"missing\").astype(str)  # Avoid NaNs + force string\n",
    "\n",
    "# Fill missing values in categorical columns with a string\n",
    "X[cat_cols] = X[cat_cols].fillna(\"missing\")\n",
    "# Optional: fill missing numeric values\n",
    "num_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "X[num_cols] = X[num_cols].fillna(0)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Define CatBoost model\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    learning_rate=0.1,\n",
    "    depth=10,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='MultiClass',\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    auto_class_weights=\"Balanced\"\n",
    ")\n",
    "\n",
    "# Train the model (using Pool to specify categorical features)\n",
    "catboost_model.fit(\n",
    "    Pool(X_train, y_train, cat_features=cat_cols),\n",
    "    eval_set=Pool(X_test, y_test, cat_features=cat_cols),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "y_pred = y_pred.flatten()  # Ensure it is 1D\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7706f310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.64      0.28   1156814\n",
      "           1       0.30      0.24      0.27      6851\n",
      "           2       1.00      0.92      0.96      2268\n",
      "           3       0.17      0.03      0.06    741116\n",
      "           4       0.17      0.27      0.21   1089894\n",
      "           5       0.00      0.00      0.00    760588\n",
      "           6       0.20      0.09      0.13    846447\n",
      "           7       0.21      0.10      0.14    837847\n",
      "           8       0.21      0.00      0.01    624071\n",
      "           9       0.00      0.00      0.00    754932\n",
      "\n",
      "    accuracy                           0.18   6820828\n",
      "   macro avg       0.25      0.23      0.21   6820828\n",
      "weighted avg       0.15      0.18      0.12   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "y = df[\"cls_detected\"]\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Fill missing, then ordinal encode categoricals\n",
    "        (\"cat\", make_pipeline(\n",
    "            SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "            OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        ), cat_cols),\n",
    "        # Fill missing in numeric columns\n",
    "        (\"num\", SimpleImputer(strategy=\"mean\"), num_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Final model pipeline\n",
    "nb_model = make_pipeline(\n",
    "    preprocessor,\n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Fit and evaluate\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ae7568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.46554 | val_accuracy: 0.71183 |  0:07:09s\n",
      "epoch 1  | loss: 0.79507 | val_accuracy: 0.71679 |  0:13:45s\n",
      "epoch 2  | loss: 0.791   | val_accuracy: 0.75038 |  0:21:23s\n",
      "epoch 3  | loss: 0.72347 | val_accuracy: 0.78978 |  0:28:25s\n",
      "epoch 4  | loss: 0.68141 | val_accuracy: 0.81268 |  0:35:32s\n",
      "epoch 5  | loss: 0.6061  | val_accuracy: 0.82589 |  0:42:51s\n",
      "epoch 6  | loss: 0.58179 | val_accuracy: 0.85227 |  0:50:49s\n",
      "epoch 7  | loss: 0.54063 | val_accuracy: 0.84328 |  0:59:21s\n",
      "\n",
      "Early stopping occurred at epoch 7 with best_epoch = 6 and best_val_accuracy = 0.85227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatihyuce/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87   1156814\n",
      "           1       0.61      0.62      0.62      6851\n",
      "           2       1.00      0.89      0.94      2268\n",
      "           3       0.88      0.84      0.86    741116\n",
      "           4       0.79      0.90      0.84   1089894\n",
      "           5       0.88      0.79      0.83    760588\n",
      "           6       0.89      0.87      0.88    846447\n",
      "           7       0.82      0.87      0.85    837847\n",
      "           8       0.80      0.81      0.81    624071\n",
      "           9       0.88      0.84      0.86    754932\n",
      "\n",
      "    accuracy                           0.85   6820828\n",
      "   macro avg       0.85      0.83      0.84   6820828\n",
      "weighted avg       0.85      0.85      0.85   6820828\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.8304\n"
     ]
    }
   ],
   "source": [
    "#TabNet\n",
    "#pip install pytorch-tabnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Target variable\n",
    "y = df[\"cls_detected\"]\n",
    "X = df.drop(\"cls_detected\", axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(\"missing\")\n",
    "\n",
    "# Encode categorical columns and collect their indices\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "cat_idxs = [X.columns.get_loc(col) for col in cat_cols]\n",
    "cat_dims = []\n",
    "\n",
    "# LabelEncode categorical columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    cat_dims.append(len(le.classes_))\n",
    "\n",
    "# Encode target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.values, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# TabNet model\n",
    "tabnet_model = TabNetClassifier(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=1,  # or use int or list like [3, 3, ...]\n",
    "    n_d=32,\n",
    "    n_a=32,\n",
    "    n_steps=5,\n",
    "    gamma=1.5,\n",
    "    lambda_sparse=1e-3,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    seed=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "tabnet_model.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=[\"accuracy\"],\n",
    "    max_epochs=10,\n",
    "    patience=1,\n",
    "    batch_size=16384,\n",
    "    virtual_batch_size=512\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred = tabnet_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", round(matthews_corrcoef(y_test, y_pred), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd901b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='17762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/17762 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 476.00 MiB (GPU 0; 1.95 GiB total capacity; 1.39 GiB already allocated; 451.62 MiB free; 1.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Build and train the model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m learn \u001b[38;5;241m=\u001b[39m tabular_learner(\n\u001b[1;32m     34\u001b[0m     dls,\n\u001b[1;32m     35\u001b[0m     layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[1;32m     36\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[accuracy, RocAuc()],\n\u001b[1;32m     37\u001b[0m     config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mps\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1\u001b[39m}  \u001b[38;5;66;03m# Correct way to pass dropout\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     43\u001b[0m preds, targs \u001b[38;5;241m=\u001b[39m learn\u001b[38;5;241m.\u001b[39mget_preds()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/callback/schedule.py:121\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    118\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    119\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    120\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:266\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:255\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:249\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:241\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:207\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:237\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    235\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:225\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb): \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_grad_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:214\u001b[0m, in \u001b[0;36mLearner._do_grad_opt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_grad_opt\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_events(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m, CancelBackwardException)\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelStepException\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:210\u001b[0m, in \u001b[0;36mLearner._step\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastai optimizers currently do not support closure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p,pg,state,hyper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_params(with_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs: state \u001b[38;5;241m=\u001b[39m _update(state, \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhyper\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[p] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/optimizer.py:162\u001b[0m, in \u001b[0;36maverage_sqr_grad\u001b[0;34m(p, sqr_mom, dampening, sqr_avg, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maverage_sqr_grad\u001b[39m(p, sqr_mom, dampening\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sqr_avg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sqr_avg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: sqr_avg \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     damp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39msqr_mom \u001b[38;5;28;01mif\u001b[39;00m dampening \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.\u001b[39m\n\u001b[1;32m    164\u001b[0m     sqr_avg\u001b[38;5;241m.\u001b[39mmul_(sqr_mom)\u001b[38;5;241m.\u001b[39maddcmul_(p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata, p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata, value\u001b[38;5;241m=\u001b[39mdamp)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 476.00 MiB (GPU 0; 1.95 GiB total capacity; 1.39 GiB already allocated; 451.62 MiB free; 1.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#fastai\n",
    "#pip install fastai\n",
    "import pandas as pd\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Fill missing values\n",
    "df = df.fillna(\"missing\")\n",
    "\n",
    "# Define target and categorical/numeric columns\n",
    "target = 'cls_detected'\n",
    "cat_names = df.select_dtypes(include='object').columns.tolist()\n",
    "cont_names = df.select_dtypes(exclude='object').drop(columns=[target]).columns.tolist()\n",
    "\n",
    "# Split train/valid sets (random 70/30 split)\n",
    "splits = RandomSplitter(seed=42)(range_of(df))\n",
    "\n",
    "# Create DataLoaders\n",
    "to = TabularPandas(\n",
    "    df,\n",
    "    procs=[Categorify, FillMissing, Normalize],\n",
    "    cat_names=cat_names,\n",
    "    cont_names=cont_names,\n",
    "    y_names=target,\n",
    "    splits=splits\n",
    ")\n",
    "\n",
    "dls = to.dataloaders(bs=1024)\n",
    "\n",
    "# Build and train the model\n",
    "learn = tabular_learner(\n",
    "    dls,\n",
    "    layers=[200, 100],\n",
    "    metrics=[accuracy, RocAuc()],\n",
    "    config={'ps': 0.1}  # Correct way to pass dropout\n",
    ")\n",
    "\n",
    "learn.fit_one_cycle(5)\n",
    "\n",
    "# Evaluate\n",
    "preds, targs = learn.get_preds()\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.print_classification_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cf18a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='2509' class='' max='17762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.13% [2509/17762 34:51&lt;3:31:54 8.3993]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m learn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m learn\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     46\u001b[0m preds, targs \u001b[38;5;241m=\u001b[39m learn\u001b[38;5;241m.\u001b[39mget_preds()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/callback/schedule.py:121\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    118\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    119\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    120\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:266\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:255\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:249\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:241\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:207\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:237\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    235\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:225\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb): \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_grad_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:214\u001b[0m, in \u001b[0;36mLearner._do_grad_opt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_grad_opt\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_events(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m, CancelBackwardException)\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelStepException\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/learner.py:210\u001b[0m, in \u001b[0;36mLearner._step\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastai optimizers currently do not support closure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p,pg,state,hyper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_params(with_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs: state \u001b[38;5;241m=\u001b[39m _update(state, \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhyper\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[p] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/fastai/optimizer.py:139\u001b[0m, in \u001b[0;36mweight_decay\u001b[0;34m(p, lr, wd, do_wd, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweight_decay\u001b[39m(p, lr, wd, do_wd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight decay as decaying `p` with `lr*wd`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m do_wd \u001b[38;5;129;01mand\u001b[39;00m wd\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#fastai no GPU\n",
    "#pip install fastai\n",
    "import pandas as pd\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "\n",
    "# Fill missing values\n",
    "df = df.fillna(\"missing\")\n",
    "\n",
    "# Define target and categorical/numeric columns\n",
    "target = 'cls_detected'\n",
    "cat_names = df.select_dtypes(include='object').columns.tolist()\n",
    "cont_names = df.select_dtypes(exclude='object').drop(columns=[target]).columns.tolist()\n",
    "\n",
    "# Split train/valid sets (random 70/30 split)\n",
    "splits = RandomSplitter(seed=42)(range_of(df))\n",
    "\n",
    "# Create DataLoaders\n",
    "to = TabularPandas(\n",
    "    df,\n",
    "    procs=[Categorify, FillMissing, Normalize],\n",
    "    cat_names=cat_names,\n",
    "    cont_names=cont_names,\n",
    "    y_names=target,\n",
    "    splits=splits\n",
    ")\n",
    "\n",
    "dls = to.dataloaders(bs=1024)\n",
    "\n",
    "# Build and train the model\n",
    "learn = tabular_learner(\n",
    "    dls,\n",
    "    layers=[200, 100],\n",
    "    metrics=[accuracy, RocAuc()],\n",
    "    config={'ps': 0.1}  # Correct way to pass dropout\n",
    ")\n",
    "\n",
    "learn.model.to(\"cpu\")\n",
    "learn.dls.device = torch.device(\"cpu\")\n",
    "\n",
    "learn.fit_one_cycle(5)\n",
    "\n",
    "# Evaluate\n",
    "preds, targs = learn.get_preds()\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.print_classification_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087ccf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 16:07:09.494855: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check the latest version manually on https://pypi.org/project/deepctr-torch/#history\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# zip inputs to feature_names\u001b[39;00m\n\u001b[1;32m     87\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m {name: x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m name, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(feature_names, x_batch)}\n\u001b[0;32m---> 89\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, y_batch)\n\u001b[1;32m     92\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 65\u001b[0m, in \u001b[0;36mDeepFMMultiClass.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/deepctr_torch/models/deepfm.py:69\u001b[0m, in \u001b[0;36mDeepFM.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 69\u001b[0m     sparse_embedding_list, dense_value_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_from_feature_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn_feature_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_model(X)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_fm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparse_embedding_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/deepctr_torch/models/basemodel.py:368\u001b[0m, in \u001b[0;36mBaseModel.input_from_feature_columns\u001b[0;34m(self, X, feature_columns, embedding_dict, support_dense)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m support_dense \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dense_feature_columns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDenseFeat is not supported in dnn_feature_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 368\u001b[0m sparse_embedding_list \u001b[38;5;241m=\u001b[39m [embedding_dict[feat\u001b[38;5;241m.\u001b[39membedding_name](\n\u001b[1;32m    369\u001b[0m     X[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index[feat\u001b[38;5;241m.\u001b[39mname][\u001b[38;5;241m0\u001b[39m]:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index[feat\u001b[38;5;241m.\u001b[39mname][\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mlong()) \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     feat \u001b[38;5;129;01min\u001b[39;00m sparse_feature_columns]\n\u001b[1;32m    372\u001b[0m sequence_embed_dict \u001b[38;5;241m=\u001b[39m varlen_embedding_lookup(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index,\n\u001b[1;32m    373\u001b[0m                                               varlen_sparse_feature_columns)\n\u001b[1;32m    374\u001b[0m varlen_sparse_embedding_list \u001b[38;5;241m=\u001b[39m get_varlen_pooling_list(sequence_embed_dict, X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index,\n\u001b[1;32m    375\u001b[0m                                                        varlen_sparse_feature_columns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/deepctr_torch/models/basemodel.py:369\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m support_dense \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dense_feature_columns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDenseFeat is not supported in dnn_feature_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    368\u001b[0m sparse_embedding_list \u001b[38;5;241m=\u001b[39m [embedding_dict[feat\u001b[38;5;241m.\u001b[39membedding_name](\n\u001b[0;32m--> 369\u001b[0m     \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlong()) \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     feat \u001b[38;5;129;01min\u001b[39;00m sparse_feature_columns]\n\u001b[1;32m    372\u001b[0m sequence_embed_dict \u001b[38;5;241m=\u001b[39m varlen_embedding_lookup(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index,\n\u001b[1;32m    373\u001b[0m                                               varlen_sparse_feature_columns)\n\u001b[1;32m    374\u001b[0m varlen_sparse_embedding_list \u001b[38;5;241m=\u001b[39m get_varlen_pooling_list(sequence_embed_dict, X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index,\n\u001b[1;32m    375\u001b[0m                                                        varlen_sparse_feature_columns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, matthews_corrcoef\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models.deepfm import DeepFM\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"burst_adma_with_cpm_multi_sensors_cls/burst_adma_with_cpm_multi_sensors999_cls_all.csv\")\n",
    "df = df.fillna(\"missing\")\n",
    "\n",
    "# Setup\n",
    "target = 'cls_detected'\n",
    "sparse_features = df.select_dtypes(include='object').columns.tolist()\n",
    "dense_features = df.select_dtypes(exclude='object').drop(columns=[target]).columns.tolist()\n",
    "\n",
    "# Label encode categoricals\n",
    "for col in sparse_features:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "# Encode target as int\n",
    "df[target] = LabelEncoder().fit_transform(df[target])\n",
    "\n",
    "# Split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature columns\n",
    "fixlen_feature_columns = [SparseFeat(feat, df[feat].nunique(), 4) for feat in sparse_features] + \\\n",
    "                         [DenseFeat(feat, 1) for feat in dense_features]\n",
    "feature_names = get_feature_names(fixlen_feature_columns)\n",
    "num_classes = df[target].nunique()\n",
    "\n",
    "# Inputs\n",
    "train_input = {name: train[name].values for name in feature_names}\n",
    "test_input = {name: test[name].values for name in feature_names}\n",
    "X_train = [torch.tensor(train_input[name]) for name in feature_names]\n",
    "X_test = [torch.tensor(test_input[name]) for name in feature_names]\n",
    "y_train = torch.tensor(train[target].values).long()\n",
    "y_test = torch.tensor(test[target].values).long()\n",
    "\n",
    "# Custom DeepFM model for multiclass\n",
    "class DeepFMMultiClass(nn.Module):\n",
    "    def __init__(self, linear_feature_columns, dnn_feature_columns, num_classes, dnn_hidden_units=(128, 64)):\n",
    "        super().__init__()\n",
    "        self.dnn_hidden_units = dnn_hidden_units\n",
    "        self.model = DeepFM(\n",
    "            linear_feature_columns, dnn_feature_columns,\n",
    "            task='binary', device='cpu',\n",
    "            dnn_hidden_units=self.dnn_hidden_units\n",
    "        )\n",
    "        self.dnn = self.model.dnn\n",
    "        self.linear_model = self.model.linear_model\n",
    "        self.embedding_dict = self.model.embedding_dict\n",
    "        self.feature_index = self.model.feature_index\n",
    "        self.bn = nn.BatchNorm1d(self.dnn_hidden_units[-1])  # ‚úÖ Now it works\n",
    "        self.output = nn.Linear(self.dnn_hidden_units[-1], num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "# Instantiate model\n",
    "model = DeepFMMultiClass(fixlen_feature_columns, fixlen_feature_columns, num_classes=num_classes)\n",
    "\n",
    "# Optimizer & loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dataloader\n",
    "train_ds = TensorDataset(*X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for batch in train_dl:\n",
    "        *x_batch, y_batch = batch\n",
    "        x_batch = [x if x.dtype == torch.float32 else x.long() for x in x_batch]\n",
    "\n",
    "        # zip inputs to feature_names\n",
    "        x_dict = {name: x.view(-1) if x.ndim == 2 and x.shape[1] == 1 else x for name, x in zip(feature_names, x_batch)}\n",
    "\n",
    "        preds = model(x_dict)\n",
    "\n",
    "        loss = criterion(preds, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_test_batch = [x.long() if x.dtype == torch.int64 else x.float() for x in X_test]\n",
    "    logits = model(x_test_batch)\n",
    "    y_pred = torch.argmax(logits, dim=1).numpy()\n",
    "    y_true = y_test.numpy()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\nPer-Class Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Metrics\n",
    "print(f\"Accuracy:         {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Macro Precision:  {precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Micro Precision:  {precision_score(y_true, y_pred, average='micro'):.4f}\")\n",
    "print(f\"Macro F1-score:   {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Micro F1-score:   {f1_score(y_true, y_pred, average='micro'):.4f}\")\n",
    "print(f\"Matthews Corrcoef:{matthews_corrcoef(y_true, y_pred):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egcnoi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
