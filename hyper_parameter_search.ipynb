{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.8847\t1\t0.9755\t0.8847\t0.9134\t0.3716\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t0.9755\t0.9692\t0.9543\t0.3716\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t0.9997\t0.9692\t0.9543\t0.3716\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t0.9997\t0.9692\t0.9544\t0.3716\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t1.0\t0.9692\t0.9544\t0.3716\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t1.0\t0.9692\t0.9546\t0.3716\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from BurstAdmaDatasetLoader import BurstAdmaDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "import json \n",
    "import time\n",
    "from graphs.recurrent.graphs_evolvegcn_h_improved import ModelOps\n",
    "import os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import json\n",
    "import time\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "MAX_PROCESS = 1 #int(mp.cpu_count()*0.7)\n",
    "num_each_threads = 1 # int(mp.cpu_count()*0.7/MAX_PROCESS) \n",
    "torch.set_num_threads(num_each_threads)\n",
    "torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "m_a = -1\n",
    "m_c = 1\n",
    "m_p = -1\n",
    "m_r = -1\n",
    "m_f = -1\n",
    "m_m = -1\n",
    " \n",
    "\n",
    "BEST_LAGS  =  [1,15,16,17,18]\n",
    "BEST_TRAIN_RATIO  =  [0.1,0.2,0.3,0.4]\n",
    "\n",
    "t = int(time.time())\n",
    "\n",
    "os.mkdir(f\"./runs/{t}\")\n",
    "\n",
    "file_name = f\"./runs/{t}/eval_metrics_{t}.csv\"\n",
    "file_name_change = f\"./runs/{t}/eval_metrics_change_{t}.csv\"\n",
    "\n",
    "\n",
    "def execute_one(loader, lags, train_ratio, num_train,current_try, lr):\n",
    "\n",
    "    # torch.set_num_threads(num_each_threads)\n",
    "    # torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "    dataset = loader.get_dataset(lags=lags)\n",
    "    # device = torch.device('cuda')\n",
    "    # dataset = dataset.to(device)\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=train_ratio)\n",
    "    ml_structure = ModelOps(lr=lr)\n",
    "    ml_structure.train(loader, train_dataset, num_train=num_train, plot_model=False,\n",
    "                       calc_perf=True)\n",
    "    metrics = ml_structure.eval(test_dataset, plot_model=False)\n",
    "    metrics[\"nt\"] = num_train\n",
    "    metrics[\"tr\"] = train_ratio\n",
    "    metrics[\"l\"] = lags\n",
    "    metrics[\"lr\"] = lr\n",
    "    # metrics[\"model\"] = ml_structure \n",
    "    # if metrics['p']>0.99 or metrics['r']>0.99 or metrics['f']>0.99  or  metrics['a']>0.99  or   metrics['m']>0.99  :\n",
    "    torch.save(ml_structure.model, f\"./runs/{t}/saved_model_{current_try}_{lr}_{lags}_{train_ratio}_{num_train }\")\n",
    "    # ml_structure.history1.progress()\n",
    "    ml_structure.history1.save(f\"./runs/{t}/saved_log_{current_try}_{lr}_{lags}_{train_ratio}_{num_train }.pkl\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_4_{current_try}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\",\"m\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_5_{current_try}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "\n",
    "    metrics[\"current_try\"] = current_try\n",
    "    # q.put(metrics)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with mp.Pool(processes=MAX_PROCESS) as pool:\n",
    "\n",
    "    with open(file_name, \"a+\") as outfile:\n",
    "        with open(file_name_change, \"a+\") as outfile_change:\n",
    "            outfile.write(\"l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "            outfile_change.write(\"l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "            async_results = []\n",
    "            loader = BurstAdmaDatasetLoader(negative_edge=False,features_as_self_edge=True)  # , negative_edge=True)\n",
    "            for lags in BEST_LAGS:#1, 21\n",
    "                # for lags in BEST_LAGS:\n",
    "                #for train_ratio in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:#\n",
    "                    train_ratio = 0.7\n",
    "                    # for train_ratio in BEST_TRAIN_RATIO:\n",
    "                    for num_train in range(1,21):\n",
    "                        for lr in [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, \\\n",
    "                                    0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, \\\n",
    "                                    0.071,0.072,0.073,0.074,0.075,0.076,0.077,0.078,0.079, \\\n",
    "                                    0.081,0.082,0.083,0.084,0.085,0.086,0.087,0.088,0.089, \\\n",
    "                                    0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, \\\n",
    "                                    0.1, 0.150, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, \\\n",
    "                                    1, 2, 3, 4, 5, 6, 7 , 8, 9]:  #\n",
    "                            # num_train = 20\n",
    "                            #metrics = execute_one(loader, lags, train_ratio, num_train)\n",
    "                            #   num_train=1\n",
    "                            current_loader = loader\n",
    "                            current_lags = lags\n",
    "                            current_train_ratio = train_ratio\n",
    "                            current_num_train = num_train\n",
    "                            current_lr = lr\n",
    "                            metrics = execute_one(current_loader, current_lags, current_train_ratio, current_num_train,t,current_lr)\n",
    "                       \n",
    "                            any_change = False\n",
    "                            a = metrics[\"a\"]\n",
    "                            if a > m_a:\n",
    "                                m_a = a\n",
    "                                any_change = True\n",
    "                            c = metrics[\"c\"]\n",
    "                            if c < m_c:\n",
    "                                m_c = c\n",
    "                                any_change = True\n",
    "                            p = metrics[\"p\"]\n",
    "                            if p > m_p:\n",
    "                                m_p = p\n",
    "                                any_change = True\n",
    "                            r = metrics[\"r\"]\n",
    "                            if r > m_r:\n",
    "                                m_r = r\n",
    "                                any_change = True\n",
    "                            f = metrics[\"f\"]\n",
    "                            if f > m_f:\n",
    "                                m_f = f\n",
    "                                any_change = True\n",
    "                            m = metrics[\"m\"]\n",
    "                            if m > m_m:\n",
    "                                m_m = m\n",
    "                                any_change = True\n",
    "                            if any_change:\n",
    "                                outfile_change.write(f\"{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                                print(\"Max So Far\")\n",
    "                                print(\"m_a\\tm_c\\tm_p\\tm_r\\tm_f\\tm_m\")\n",
    "                                print(f\"{round(m_a, 4)}\\t{round(m_c, 4)}\\t{round(m_p, 4)}\\t{round(m_r, 4)}\\t{round(m_f, 4)}\\t{round(m_m, 4)}\")\n",
    "                                # torch.save(metrics[\"model\"].model, f\"split1/saved_model_{metrics['current_try']}_{metrics['l']}_{metrics['tr']}_{metrics['nt']}\")\n",
    "                            outfile.write(f\"{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                            outfile.flush()\n",
    "                            outfile_change.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_a,m_c,m_p ,m_r ,m_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egcnoi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
