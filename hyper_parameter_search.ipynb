{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9527\t1\t0.971\t0.9527\t0.9476\t0.0224\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9527\t1\t0.9741\t0.9527\t0.9476\t0.0247\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t0.9741\t0.9692\t0.9543\t0.0247\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t0.9741\t0.9692\t0.9543\t0.0476\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9692\t1\t0.9758\t0.9692\t0.9568\t0.208\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9694\t1\t0.9758\t0.9694\t0.9568\t0.208\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9694\t1\t0.996\t0.9694\t0.9568\t0.208\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9694\t1\t0.9992\t0.9694\t0.9568\t0.208\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9694\t1\t1.0\t0.9694\t0.9568\t0.208\n",
      "Max So Far\n",
      "m_a\tm_c\tm_p\tm_r\tm_f\tm_m\n",
      "0.9709\t1\t1.0\t0.9709\t0.9579\t0.2644\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m\n\u001b[1;32m    102\u001b[0m current_num_train \u001b[38;5;241m=\u001b[39m num_train\n\u001b[1;32m    103\u001b[0m current_lr \u001b[38;5;241m=\u001b[39m lr\n\u001b[0;32m--> 104\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_lags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_train_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_num_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcurrent_lr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m any_change \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    107\u001b[0m a \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m, in \u001b[0;36mexecute_one\u001b[0;34m(loader, lags, train_ratio, num_train, current_try, lr)\u001b[0m\n\u001b[1;32m     49\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m temporal_signal_split(dataset, train_ratio\u001b[38;5;241m=\u001b[39mtrain_ratio)\n\u001b[1;32m     50\u001b[0m ml_structure \u001b[38;5;241m=\u001b[39m ModelOps(lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mml_structure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcalc_perf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m metrics \u001b[38;5;241m=\u001b[39m ml_structure\u001b[38;5;241m.\u001b[39meval(test_dataset, plot_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_train\n",
      "File \u001b[0;32m~/work/projects/v2x/graf/EvolveGCNOi_CPM/graphs/recurrent/graphs_evolvegcn_h_improved.py:85\u001b[0m, in \u001b[0;36mModelOps.train\u001b[0;34m(self, loader, train_dataset, num_train, plot_model, calc_perf, scriptable)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scriptable:\n\u001b[1;32m     83\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mscript(model)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnum_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mplot_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcalc_perf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalc_perf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/projects/v2x/graf/EvolveGCNOi_CPM/graphs/recurrent/graphs_base.py:246\u001b[0m, in \u001b[0;36mBaseGrafModelOps.train\u001b[0;34m(self, loader, train_dataset, model, num_train, plot_model, calc_perf)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost \u001b[38;5;241m/\u001b[39m (time\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# if plot_model:\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m#     self.plot([\"a\",\"p\",\"r\",\"f\"])\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    248\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from BurstAdmaDatasetLoader import BurstAdmaDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "import json \n",
    "import time\n",
    "from graphs.recurrent.graphs_evolvegcn_h_improved import ModelOps\n",
    "import os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import json\n",
    "import time\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "MAX_PROCESS = 1 #int(mp.cpu_count()*0.7)\n",
    "num_each_threads = 1 # int(mp.cpu_count()*0.7/MAX_PROCESS) \n",
    "torch.set_num_threads(num_each_threads)\n",
    "torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "m_a = -1\n",
    "m_c = 1\n",
    "m_p = -1\n",
    "m_r = -1\n",
    "m_f = -1\n",
    "m_m = -1\n",
    " \n",
    "\n",
    "BEST_LAGS  =  [1,15,16,17,18]\n",
    "BEST_TRAIN_RATIO  =  [0.1,0.2,0.3,0.4]\n",
    "\n",
    "t = int(time.time())\n",
    "\n",
    "os.mkdir(f\"./runs/{t}\")\n",
    "\n",
    "file_name = f\"./runs/{t}/eval_metrics_{t}.csv\"\n",
    "file_name_change = f\"./runs/{t}/eval_metrics_change_{t}.csv\"\n",
    "\n",
    "\n",
    "def execute_one(loader, lags, train_ratio, num_train,current_try, lr):\n",
    "\n",
    "    # torch.set_num_threads(num_each_threads)\n",
    "    # torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "    dataset = loader.get_dataset(lags=lags)\n",
    "    # device = torch.device('cuda')\n",
    "    # dataset = dataset.to(device)\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=train_ratio)\n",
    "    ml_structure = ModelOps(lr=lr)\n",
    "    ml_structure.train(loader, train_dataset, num_train=num_train, plot_model=False,\n",
    "                       calc_perf=True)\n",
    "    metrics = ml_structure.eval(test_dataset, plot_model=False)\n",
    "    metrics[\"nt\"] = num_train\n",
    "    metrics[\"tr\"] = train_ratio\n",
    "    metrics[\"l\"] = lags\n",
    "    metrics[\"lr\"] = lr\n",
    "    # metrics[\"model\"] = ml_structure \n",
    "    # if metrics['p']>0.99 or metrics['r']>0.99 or metrics['f']>0.99  or  metrics['a']>0.99  or   metrics['m']>0.99  :\n",
    "    torch.save(ml_structure.model, f\"./runs/{t}/saved_model_{current_try}_{lr}_{lags}_{train_ratio}_{num_train }\")\n",
    "    # ml_structure.history1.progress()\n",
    "    ml_structure.history1.save(f\"./runs/{t}/saved_log_{current_try}_{lr}_{lags}_{train_ratio}_{num_train }.pkl\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_4_{current_try}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\",\"m\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_5_{current_try}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "\n",
    "    metrics[\"current_try\"] = current_try\n",
    "    # q.put(metrics)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with mp.Pool(processes=MAX_PROCESS) as pool:\n",
    "\n",
    "with open(file_name, \"a+\") as outfile:\n",
    "    with open(file_name_change, \"a+\") as outfile_change:\n",
    "        outfile.write(\"l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "        outfile_change.write(\"l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "        async_results = []\n",
    "        loader = BurstAdmaDatasetLoader(negative_edge=False,features_as_self_edge=True)  # , negative_edge=True)\n",
    "        for lags in BEST_LAGS:#1, 21\n",
    "            # for lags in BEST_LAGS:\n",
    "            #for train_ratio in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:#\n",
    "                train_ratio = 0.7\n",
    "                # for train_ratio in BEST_TRAIN_RATIO:\n",
    "                for num_train in range(1,21):\n",
    "                    for lr in [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, \\\n",
    "                                0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, \\\n",
    "                                0.071,0.072,0.073,0.074,0.075,0.076,0.077,0.078,0.079, \\\n",
    "                                0.081,0.082,0.083,0.084,0.085,0.086,0.087,0.088,0.089, \\\n",
    "                                0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, \\\n",
    "                                0.1, 0.150, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, \\\n",
    "                                1, 2, 3, 4, 5, 6, 7 , 8, 9]:  #\n",
    "                        # num_train = 20\n",
    "                        #metrics = execute_one(loader, lags, train_ratio, num_train)\n",
    "                        #   num_train=1\n",
    "                        current_loader = loader\n",
    "                        current_lags = lags\n",
    "                        current_train_ratio = train_ratio\n",
    "                        current_num_train = num_train\n",
    "                        current_lr = lr\n",
    "                        metrics = execute_one(current_loader, current_lags, current_train_ratio, current_num_train,t,current_lr)\n",
    "                    \n",
    "                        any_change = False\n",
    "                        a = metrics[\"a\"]\n",
    "                        if a > m_a:\n",
    "                            m_a = a\n",
    "                            any_change = True\n",
    "                        c = metrics[\"c\"]\n",
    "                        if c < m_c:\n",
    "                            m_c = c\n",
    "                            any_change = True\n",
    "                        p = metrics[\"p\"]\n",
    "                        if p > m_p:\n",
    "                            m_p = p\n",
    "                            any_change = True\n",
    "                        r = metrics[\"r\"]\n",
    "                        if r > m_r:\n",
    "                            m_r = r\n",
    "                            any_change = True\n",
    "                        f = metrics[\"f\"]\n",
    "                        if f > m_f:\n",
    "                            m_f = f\n",
    "                            any_change = True\n",
    "                        m = metrics[\"m\"]\n",
    "                        if m > m_m:\n",
    "                            m_m = m\n",
    "                            any_change = True\n",
    "                        if any_change:\n",
    "                            outfile_change.write(f\"{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                            print(\"Max So Far\")\n",
    "                            print(\"m_a\\tm_c\\tm_p\\tm_r\\tm_f\\tm_m\")\n",
    "                            print(f\"{round(m_a, 4)}\\t{round(m_c, 4)}\\t{round(m_p, 4)}\\t{round(m_r, 4)}\\t{round(m_f, 4)}\\t{round(m_m, 4)}\")\n",
    "                            # torch.save(metrics[\"model\"].model, f\"split1/saved_model_{metrics['current_try']}_{metrics['l']}_{metrics['tr']}_{metrics['nt']}\")\n",
    "                        outfile.write(f\"{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                        outfile.flush()\n",
    "                        outfile_change.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from BurstAdmaDatasetLoader import BurstAdmaDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "import json \n",
    "import time\n",
    "from graphs.recurrent.graphs_evolvegcn_h_improved import ModelOps\n",
    "import os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import json\n",
    "import time\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "MAX_PROCESS = 1 #int(mp.cpu_count()*0.7)\n",
    "num_each_threads = 1 # int(mp.cpu_count()*0.7/MAX_PROCESS) \n",
    "torch.set_num_threads(num_each_threads)\n",
    "torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "m_a = -1\n",
    "m_c = 1\n",
    "m_p = -1\n",
    "m_r = -1\n",
    "m_f = -1\n",
    "m_m = -1\n",
    " \n",
    "\n",
    "BEST_LAGS  =  [1,15,16,17,18]\n",
    "BEST_TRAIN_RATIO  =  [0.1,0.2,0.3,0.4]\n",
    "\n",
    "t = int(time.time())\n",
    "\n",
    "os.mkdir(f\"./runs/{t}\")\n",
    "\n",
    "file_name = f\"./runs/{t}/eval_metrics_{t}.csv\"\n",
    "file_name_change = f\"./runs/{t}/eval_metrics_change_{t}.csv\"\n",
    "\n",
    "\n",
    "def execute_one(loader, lags, train_ratio, num_train,current_try, lr):\n",
    "\n",
    "    # torch.set_num_threads(num_each_threads)\n",
    "    # torch.set_num_interop_threads(num_each_threads)\n",
    "\n",
    "    dataset = loader.get_dataset(lags=lags)\n",
    "    # device = torch.device('cuda')\n",
    "    # dataset = dataset.to(device)\n",
    "    train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=train_ratio)\n",
    "    ml_structure = ModelOps(lr=lr)\n",
    "    ml_structure.train(loader, train_dataset, num_train=num_train, plot_model=False,\n",
    "                       calc_perf=True)\n",
    "    metrics = ml_structure.eval(test_dataset, plot_model=False)\n",
    "    metrics[\"nt\"] = num_train\n",
    "    metrics[\"tr\"] = train_ratio\n",
    "    metrics[\"l\"] = lags\n",
    "    metrics[\"lr\"] = lr\n",
    "    # metrics[\"model\"] = ml_structure \n",
    "    # if metrics['p']>0.99 or metrics['r']>0.99 or metrics['f']>0.99  or  metrics['a']>0.99  or   metrics['m']>0.99  :\n",
    "    torch.save(ml_structure.model, f\"./runs/{t}/saved_model_{current_try}_{lr}_{lags}_{train_ratio}_{num_train }\")\n",
    "    # ml_structure.history1.progress()\n",
    "    ml_structure.history1.save(f\"./runs/{t}/saved_log_{current_try}_{lr}_{lags}_{train_ratio}_{num_train }.pkl\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_4_{current_try}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "    # ml_structure.plot([\"a\",\"p\",\"r\",\"f\",\"m\"])\n",
    "    # ml_structure.save_after_plot(f\"split1/saved_plot_5_{current_try}_{lags}_{train_ratio}_{num_train }.png\")\n",
    "\n",
    "    metrics[\"current_try\"] = current_try\n",
    "    # q.put(metrics)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with mp.Pool(processes=MAX_PROCESS) as pool:\n",
    "\n",
    "    with open(file_name, \"a+\") as outfile:\n",
    "        with open(file_name_change, \"a+\") as outfile_change:\n",
    "            outfile.write(\"l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "            outfile_change.write(\"l,t,nt,lr,p,r,f,a,c,m\\n\")\n",
    "            async_results = []\n",
    "            loader = BurstAdmaDatasetLoader(negative_edge=False,features_as_self_edge=True)  # , negative_edge=True)\n",
    "            for lags in BEST_LAGS:#1, 21\n",
    "                # for lags in BEST_LAGS:\n",
    "                #for train_ratio in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:#\n",
    "                    train_ratio = 0.7\n",
    "                    # for train_ratio in BEST_TRAIN_RATIO:\n",
    "                    for num_train in range(1,21):\n",
    "                        for lr in [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, \\\n",
    "                                    0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, \\\n",
    "                                    0.071,0.072,0.073,0.074,0.075,0.076,0.077,0.078,0.079, \\\n",
    "                                    0.081,0.082,0.083,0.084,0.085,0.086,0.087,0.088,0.089, \\\n",
    "                                    0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, \\\n",
    "                                    0.1, 0.150, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, \\\n",
    "                                    1, 2, 3, 4, 5, 6, 7 , 8, 9]:  #\n",
    "                            # num_train = 20\n",
    "                            #metrics = execute_one(loader, lags, train_ratio, num_train)\n",
    "                            #   num_train=1\n",
    "                            current_loader = loader\n",
    "                            current_lags = lags\n",
    "                            current_train_ratio = train_ratio\n",
    "                            current_num_train = num_train\n",
    "                            current_lr = lr\n",
    "                            async_results.append(pool.apply_async(execute_one, args=(current_loader, current_lags, current_train_ratio, current_num_train,t,current_lr)))\n",
    "\n",
    "            for i, async_result in enumerate(async_results):\n",
    "                metrics = async_result.get()\n",
    "                any_change = False\n",
    "                a = metrics[\"a\"]\n",
    "                if a > m_a:\n",
    "                    m_a = a\n",
    "                    any_change = True\n",
    "                c = metrics[\"c\"]\n",
    "                if c < m_c:\n",
    "                    m_c = c\n",
    "                    any_change = True\n",
    "                p = metrics[\"p\"]\n",
    "                if p > m_p:\n",
    "                    m_p = p\n",
    "                    any_change = True\n",
    "                r = metrics[\"r\"]\n",
    "                if r > m_r:\n",
    "                    m_r = r\n",
    "                    any_change = True\n",
    "                f = metrics[\"f\"]\n",
    "                if f > m_f:\n",
    "                    m_f = f\n",
    "                    any_change = True\n",
    "                m = metrics[\"m\"]\n",
    "                if m > m_m:\n",
    "                    m_m = m\n",
    "                    any_change = True\n",
    "                if any_change:\n",
    "                    outfile_change.write(f\"{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                    print(\"Max So Far\")\n",
    "                    print(\"m_a\\tm_c\\tm_p\\tm_r\\tm_f\\tm_m\")\n",
    "                    print(f\"{round(m_a, 4)}\\t{round(m_c, 4)}\\t{round(m_p, 4)}\\t{round(m_r, 4)}\\t{round(m_f, 4)}\\t{round(m_m, 4)}\")\n",
    "                    # torch.save(metrics[\"model\"].model, f\"split1/saved_model_{metrics['current_try']}_{metrics['l']}_{metrics['tr']}_{metrics['nt']}\")\n",
    "                outfile.write(f\"{metrics['l']},{metrics['tr']},{metrics['nt']},{metrics['lr']},{metrics['p']},{metrics['r']},{metrics['f']},{metrics['a']},{metrics['c']},{metrics['m']}\\n\")\n",
    "                outfile.flush()\n",
    "                outfile_change.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_a,m_c,m_p ,m_r ,m_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egcnoi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
