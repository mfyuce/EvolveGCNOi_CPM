{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Constrained Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:02<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset saved as burst_adma_with_cpm.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load BurST-ADMA dataset (Assuming CSV format)\n",
    "file_path = \"imported_data/BurST-ADMA_v0.1.csv\"  # Update with actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant fields\n",
    "vehicles = data[['id', 'timestep', 'x', 'y', 'speed', 'heading','acceleration']]\n",
    "\n",
    "# Define sensor range (meters)\n",
    "SENSOR_RANGE = 50\n",
    "\n",
    "# Function to simulate CPM detection\n",
    "def generate_cpm(vehicles, sensor_range=SENSOR_RANGE):\n",
    "    cpm_data = []\n",
    "    timestamps = vehicles['timestep'].unique()\n",
    "    \n",
    "    for t in tqdm(timestamps):\n",
    "        snapshot = vehicles[vehicles['timestep'] == t]\n",
    "        positions = snapshot[['x', 'y']].values\n",
    "        ids = snapshot['id'].values\n",
    "        kd_tree = KDTree(positions)\n",
    "        \n",
    "        for i, (vid, pos) in enumerate(zip(ids, positions)):\n",
    "            # Find nearest neighbors within sensor range\n",
    "            indices = kd_tree.query_ball_point(pos, sensor_range)\n",
    "            \n",
    "            detected_objects = []\n",
    "            for idx in indices:\n",
    "                if idx != i:  # Exclude self\n",
    "                    detected_objects.append({\n",
    "                        'detected_id': ids[idx],\n",
    "                        'x_detected': positions[idx][0] + np.random.normal(0, 1),  # Add noise\n",
    "                        'y_detected': positions[idx][1] + np.random.normal(0, 1)\n",
    "                    })\n",
    "            \n",
    "            # Create CPM entry\n",
    "            cpm_data.append({\n",
    "                'id': vid,\n",
    "                'timestep': t,\n",
    "                'detected_objects': detected_objects\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(cpm_data)\n",
    "\n",
    "# Generate CPM dataset\n",
    "cpm_dataset = generate_cpm(vehicles)\n",
    "\n",
    "# Save enhanced dataset\n",
    "cpm_dataset.to_csv(\"burst_adma_with_cpm.csv\", index=False)\n",
    "print(\"CPM-enhanced dataset saved as burst_adma_with_cpm.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. +Extended Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:45<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset saved as burst_adma_with_cpm.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load BurST-ADMA dataset (Assuming CSV format)\n",
    "file_path = \"imported_data/BurST-ADMA_v0.1.csv\"  # Update with actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant fields\n",
    "vehicles = data[['id', 'timestep', 'x', 'y', 'speed', 'heading','acceleration']]\n",
    "\n",
    "# Define sensor range (meters)\n",
    "SENSOR_RANGE = 50\n",
    "SENSOR_TYPE = \"LiDAR\"\n",
    "\n",
    "# Function to simulate CPM detection\n",
    "def generate_cpm(vehicles, sensor_range=SENSOR_RANGE):\n",
    "    cpm_data = []\n",
    "    timestamps = vehicles['timestep'].unique()\n",
    "    \n",
    "    for t in tqdm(timestamps):\n",
    "        snapshot = vehicles[vehicles['timestep'] == t]\n",
    "        positions = snapshot[['x', 'y']].values\n",
    "        ids = snapshot['id'].values\n",
    "        velocities = snapshot['speed'].values\n",
    "        headings = snapshot['heading'].values\n",
    "        accelerations = snapshot['acceleration'].values\n",
    "        kd_tree = KDTree(positions)\n",
    "        \n",
    "        for i, (vid, pos, vel, head) in enumerate(zip(ids, positions, velocities, headings,accelerations)):\n",
    "            # Find nearest neighbors within sensor range\n",
    "            indices = kd_tree.query_ball_point(pos, sensor_range)\n",
    "            \n",
    "            detected_objects = []\n",
    "            for idx in indices:\n",
    "                if idx != i:  # Exclude self\n",
    "                    detected_objects.append({\n",
    "                        'detected_id': ids[idx],\n",
    "                        'x_detected': positions[idx][0] + np.random.normal(0, 1),  # Add noise\n",
    "                        'y_detected': positions[idx][1] + np.random.normal(0, 1),\n",
    "                        'speed_detected': velocities[idx] + np.random.normal(0, 0.5),\n",
    "                        'heading_detected': headings[idx] + np.random.normal(0, 1),\n",
    "                        'acceleration_detected': accelerations[idx] + np.random.normal(0, 1),\n",
    "                        'object_type': 'vehicle',  # Assuming vehicles for now\n",
    "                        'detection_confidence': np.random.uniform(0.8, 1.0)  # High confidence\n",
    "                    })\n",
    "            \n",
    "            # Create CPM entry\n",
    "            cpm_data.append({\n",
    "                'cpm_id': f\"CPM_{vid}_{t}\",\n",
    "                'id': vid,\n",
    "                'timestep': t,\n",
    "                'sensor_id': f\"Sensor_{vid}\",\n",
    "                'sensor_type': SENSOR_TYPE,\n",
    "                'weather_conditions': 'clear',  # Placeholder\n",
    "                'visibility_range': sensor_range,\n",
    "                'detected_objects': detected_objects\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(cpm_data)\n",
    "\n",
    "# Generate CPM dataset\n",
    "cpm_dataset = generate_cpm(vehicles)\n",
    "\n",
    "# Save enhanced dataset\n",
    "cpm_dataset.to_csv(\"burst_adma_with_cpm_enhanced.csv\", index=False)\n",
    "print(\"CPM-enhanced dataset saved as burst_adma_with_cpm.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. +Environment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [06:04,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset saved as burst_adma_with_cpm_and_env.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load BurST-ADMA dataset (Assuming CSV format)\n",
    "file_path = \"imported_data/BurST-ADMA_v0.1.csv\"  # Update with actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant fields\n",
    "vehicles = data[['id', 'timestep', 'x', 'y', 'speed', 'heading','acceleration']]\n",
    "\n",
    "# Define sensor range (meters)\n",
    "SENSOR_RANGE = 50\n",
    "SENSOR_TYPE = \"LiDAR\"\n",
    "\n",
    "# Function to simulate CPM detection\n",
    "def generate_cpm(vehicles, sensor_range=SENSOR_RANGE):\n",
    "    cpm_data = []\n",
    "    timestamps = vehicles['timestep'].unique()\n",
    "    \n",
    "    # Simulate environmental conditions\n",
    "    weather_conditions = np.random.choice(['clear', 'foggy', 'rainy', 'snowy'], size=len(timestamps))\n",
    "    visibility_ranges = {\n",
    "        'clear': 100,\n",
    "        'foggy': 30,\n",
    "        'rainy': 50,\n",
    "        'snowy': 40\n",
    "    }\n",
    "    \n",
    "    for idx, t in tqdm(enumerate(timestamps)):\n",
    "        snapshot = vehicles[vehicles['timestep'] == t]\n",
    "        positions = snapshot[['x', 'y']].values\n",
    "        vehicle_ids = snapshot['id'].values\n",
    "        velocities = snapshot['speed'].values\n",
    "        headings = snapshot['heading'].values\n",
    "        accelerations = snapshot['acceleration'].values\n",
    "        kd_tree = KDTree(positions)\n",
    "        \n",
    "        current_weather = weather_conditions[idx]\n",
    "        visibility_range = visibility_ranges[current_weather]\n",
    "        \n",
    "        for i, (vid, pos, vel, head,acceleration) in enumerate(zip(vehicle_ids, positions, velocities, headings,accelerations)):\n",
    "            # Find nearest neighbors within sensor range\n",
    "            indices = kd_tree.query_ball_point(pos, min(sensor_range, visibility_range))\n",
    "            \n",
    "            detected_objects = []\n",
    "            for idx in indices:\n",
    "                if idx != i:  # Exclude self\n",
    "                    detected_objects.append({\n",
    "                        'detected_vehicle_id': vehicle_ids[idx],\n",
    "                        'x_detected': positions[idx][0] + np.random.normal(0, 1),  # Add noise\n",
    "                        'y_detected': positions[idx][1] + np.random.normal(0, 1),\n",
    "                        'velocity_detected': velocities[idx] + np.random.normal(0, 0.5),\n",
    "                        'heading_detected': headings[idx] + np.random.normal(0, 1),\n",
    "                        'acceleration_detected': accelerations[idx] + np.random.normal(0, 1),\n",
    "                        'object_type': 'vehicle',  # Assuming vehicles for now\n",
    "                        'detection_confidence': np.random.uniform(0.6, 1.0)  # Varies with weather\n",
    "                    })\n",
    "            \n",
    "            # Create CPM entry\n",
    "            cpm_data.append({\n",
    "                'cpm_id': f\"CPM_{vid}_{t}\",\n",
    "                'id': vid,\n",
    "                'timestep': t,\n",
    "                'sensor_id': f\"Sensor_{vid}\",\n",
    "                'sensor_type': SENSOR_TYPE,\n",
    "                'weather_conditions': current_weather,\n",
    "                'visibility_range': visibility_range,\n",
    "                'detected_objects': detected_objects\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(cpm_data)\n",
    "\n",
    "# Generate CPM dataset\n",
    "cpm_dataset = generate_cpm(vehicles)\n",
    "\n",
    "# Save enhanced dataset\n",
    "cpm_dataset.to_csv(\"burst_adma_with_cpm_and_env.csv\", index=False)\n",
    "print(\"CPM-enhanced dataset saved as burst_adma_with_cpm_and_env.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. +Multiple Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [00:31,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors199.0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "399it [03:42,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors399.0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "599it [10:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors599.0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "799it [20:38,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors799.0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [33:41,  2.43s/it] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load BurST-ADMA dataset (Assuming CSV format)\n",
    "file_path = \"imported_data/BurST-ADMA_v0.1.csv\"  # Update with actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant fields\n",
    "vehicles = data[['id', 'timestep', 'x', 'y', 'speed', 'heading','acceleration']]\n",
    "\n",
    "# Define sensor range (meters)\n",
    "SENSOR_TYPES = [\"LiDAR\", \"Camera\", \"Radar\"]\n",
    "SENSOR_RANGES = {\"LiDAR\": 50, \"Camera\": 40, \"Radar\": 80}\n",
    "MAX_TS=200\n",
    "# Function to extract object type from vehicle ID\n",
    "def extract_object_type(id):\n",
    "    if id.startswith('bike') :\n",
    "        return 'bicycle'\n",
    "    elif id.startswith('bus') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('moto') :\n",
    "        return 'motorcycle'\n",
    "    elif id.startswith('ped') :\n",
    "       return 'pedestrian'\n",
    "    elif id.startswith('pt_bus_') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('pt_tram_') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('truck') :\n",
    "        return 'truck'\n",
    "    elif id.startswith('veh') :\n",
    "        return 'vehicle'\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "def save_ds(current_ts, cpm_data,detected_objects):\n",
    "    # Save enhanced dataset\n",
    "    cpm_dataset=pd.DataFrame(cpm_data)\n",
    "    cpm_dataset.to_csv(f\"burst_adma_with_cpm_multi_sensors/burst_adma_with_cpm_multi_sensors{current_ts}.csv\", index=False)\n",
    "    cpm_dataset=None\n",
    "    cpm_dataset=pd.DataFrame(detected_objects)\n",
    "    cpm_dataset.to_csv(f\"burst_adma_with_cpm_multi_sensors/burst_adma_with_cpm_multi_sensors{current_ts}_detected_objects.csv\", index=False)\n",
    "    cpm_dataset=None\n",
    "    print(f\"CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors{current_ts}.csv\")\n",
    "  \n",
    "\n",
    "# Function to simulate CPM detection with multiple sensors\n",
    "def generate_cpm(vehicles, sensor_types=SENSOR_TYPES, sensor_ranges=SENSOR_RANGES):\n",
    "    cpm_data = []\n",
    "    detected_objects = []\n",
    "    timestamps = vehicles['timestep'].unique()\n",
    "    \n",
    "    # Simulate environmental conditions\n",
    "    weather_conditions = np.random.choice(['clear', 'foggy', 'rainy', 'snowy'], size=len(timestamps))\n",
    "    visibility_ranges = {\n",
    "        'clear': 100,\n",
    "        'foggy': 30,\n",
    "        'rainy': 50,\n",
    "        'snowy': 40\n",
    "    }\n",
    "    current_ts=0\n",
    "    for idx, t in tqdm(enumerate(timestamps)):\n",
    "        current_ts+=1\n",
    "        if current_ts % MAX_TS==0:\n",
    "            # Save enhanced dataset\n",
    "            save_ds(t, cpm_data,detected_objects)\n",
    "            cpm_data = [] \n",
    "            detected_objects=[]\n",
    "        snapshot = vehicles[vehicles['timestep'] == t]\n",
    "        positions = snapshot[['x', 'y']].values\n",
    "        vehicle_ids = snapshot['id'].values\n",
    "        velocities = snapshot['speed'].values\n",
    "        headings = snapshot['heading'].values\n",
    "        accelerations = snapshot['acceleration'].values\n",
    "        kd_tree = KDTree(positions)\n",
    "        \n",
    "        current_weather = weather_conditions[idx]\n",
    "        visibility_range = visibility_ranges[current_weather]\n",
    "        \n",
    "        for i, (vid, pos, vel, head,acceleration) in enumerate(zip(vehicle_ids, positions, velocities, headings,accelerations)):\n",
    "            object_type = extract_object_type(vid)  # Extract object type from ID\n",
    "            for sensor in sensor_types:\n",
    "                sensor_range = min(sensor_ranges[sensor], visibility_range)\n",
    "                \n",
    "                # Find nearest neighbors within sensor range\n",
    "                indices = kd_tree.query_ball_point(pos, sensor_range)\n",
    "                \n",
    "                for idx in indices:\n",
    "                    if idx != i:  # Exclude self\n",
    "                        detected_objects.append({\n",
    "                            'cpm_id': f\"CPM_{vid}_{t}_{sensor}\",\n",
    "                            'detected_vehicle_id': vehicle_ids[idx],\n",
    "                            'x_detected': positions[idx][0] + np.random.normal(0, 1),  # Add noise\n",
    "                            'y_detected': positions[idx][1] + np.random.normal(0, 1),\n",
    "                            'velocity_detected': velocities[idx] + np.random.normal(0, 0.5),\n",
    "                            'heading_detected': headings[idx] + np.random.normal(0, 1),\n",
    "                            'acceleration_detected': accelerations[idx] + np.random.normal(0, 1),\n",
    "                            'object_type': extract_object_type(vehicle_ids[idx]),\n",
    "                            'detection_confidence': np.random.uniform(0.6, 1.0)  # Varies with weather\n",
    "                        })\n",
    "                \n",
    "                # Create CPM entry\n",
    "                cpm_data.append({\n",
    "                    'cpm_id': f\"CPM_{vid}_{t}_{sensor}\",\n",
    "                    'vehicle_id': vid,\n",
    "                    'timestep': t,\n",
    "                    'sensor_id': f\"Sensor_{vid}_{sensor}\",\n",
    "                    'sensor_type': sensor,\n",
    "                    'sensor_range': sensor_range,\n",
    "                    'weather_conditions': current_weather,\n",
    "                    'visibility_range': visibility_range,\n",
    "                    'object_type': object_type,\n",
    "                    #'detected_objects': detected_objects\n",
    "                })\n",
    "    if cpm_data:\n",
    "        # Save enhanced dataset\n",
    "        save_ds(t, cpm_data,detected_objects)\n",
    "        cpm_data = [] \n",
    "        detected_objects=[]\n",
    "    # return pd.DataFrame(cpm_data)\n",
    "\n",
    "# Generate CPM dataset\n",
    "generate_cpm(vehicles)\n",
    "\n",
    "# # Save enhanced dataset\n",
    "# cpm_dataset.to_csv(\"burst_adma_with_cpm_multi_sensors.csv\", index=False)\n",
    "# print(\"CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors.csv\")\n",
    "# import sqlite3\n",
    "# # Create your connection.\n",
    "# cnx = sqlite3.connect('imported_data/burst_adma_with_cpm_multi_sensors.db')\n",
    "# cpm_dataset.to_sql(name='burst_adma_with_cpm_multi_sensors', con=cnx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. +Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [03:27,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors999_cls.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load BurST-ADMA dataset (Assuming CSV format)\n",
    "file_path = \"data/burst_adma_with_clusters_in_time.csv\"  # Update with actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant fields\n",
    "vehicles = data[['id', 'timestep', 'x', 'y', 'speed', 'heading','acceleration','label','cls']]\n",
    "\n",
    "# Define sensor range (meters)\n",
    "SENSOR_TYPES = [\"LiDAR\", \"Camera\", \"Radar\"]\n",
    "SENSOR_RANGES = {\"LiDAR\": 50, \"Camera\": 40, \"Radar\": 80}\n",
    "MAX_TS=1000\n",
    "FOLDER_TO_SAVE=\"burst_adma_with_cpm_multi_sensors_cls\"\n",
    "# Function to extract object type from vehicle ID\n",
    "def extract_object_type(id):\n",
    "    if id.startswith('bike') :\n",
    "        return 'bicycle'\n",
    "    elif id.startswith('bus') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('moto') :\n",
    "        return 'motorcycle'\n",
    "    elif id.startswith('ped') :\n",
    "       return 'pedestrian'\n",
    "    elif id.startswith('pt_bus_') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('pt_tram_') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('truck') :\n",
    "        return 'truck'\n",
    "    elif id.startswith('veh') :\n",
    "        return 'vehicle'\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "def save_ds(current_ts, cpm_data,detected_objects,all_objects):\n",
    "    # Save cam+cpm dataset\n",
    "    cpm_dataset=pd.DataFrame(all_objects)\n",
    "    cpm_dataset.to_csv(f\"{FOLDER_TO_SAVE}/burst_adma_with_cpm_multi_sensors{int(current_ts)}_cls_all.csv\", index=False)\n",
    "    cpm_dataset=None\n",
    "    # Save cam dataset\n",
    "    cpm_dataset=pd.DataFrame(cpm_data)\n",
    "    cpm_dataset.to_csv(f\"{FOLDER_TO_SAVE}/burst_adma_with_cpm_multi_sensors{int(current_ts)}_cls.csv\", index=False)\n",
    "    cpm_dataset=None \n",
    "    # Save cpm dataset\n",
    "    cpm_dataset=pd.DataFrame(detected_objects)\n",
    "    cpm_dataset.to_csv(f\"{FOLDER_TO_SAVE}/burst_adma_with_cpm_multi_sensors{int(current_ts)}_cls_detected_objects.csv\", index=False)\n",
    "    cpm_dataset=None\n",
    "    print(f\"CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors{int(current_ts)}_cls.csv\")\n",
    "  \n",
    "\n",
    "# Function to simulate CPM detection with multiple sensors\n",
    "def generate_cpm(vehicles, sensor_types=SENSOR_TYPES, sensor_ranges=SENSOR_RANGES):\n",
    "    cpm_data = []\n",
    "    detected_objects = []\n",
    "    all_objects = []\n",
    "    timestamps = vehicles['timestep'].unique()\n",
    "    \n",
    "    # Simulate environmental conditions\n",
    "    weather_conditions = np.random.choice(['clear', 'foggy', 'rainy', 'snowy'], size=len(timestamps))\n",
    "    visibility_ranges = {\n",
    "        'clear': 100,\n",
    "        'foggy': 30,\n",
    "        'rainy': 50,\n",
    "        'snowy': 40\n",
    "    }\n",
    "    current_ts=0\n",
    "    for idx, t in tqdm(enumerate(timestamps)):\n",
    "        if cpm_data and current_ts % MAX_TS==0:\n",
    "            # Save enhanced dataset\n",
    "            save_ds(t, cpm_data,detected_objects,all_objects)\n",
    "            cpm_data = [] \n",
    "            detected_objects=[]\n",
    "            all_objects=[]\n",
    "\n",
    "            \n",
    "        current_weather = weather_conditions[idx]\n",
    "        visibility_range = visibility_ranges[current_weather]\n",
    "\n",
    "        clasess = vehicles['cls'].unique()\n",
    "        snapshot_v = vehicles[vehicles['timestep'] == t]\n",
    "        for idx_cls, t_cls in enumerate(clasess):\n",
    "            snapshot = snapshot_v[snapshot_v['cls'] == t_cls]\n",
    "            positions = snapshot[['x', 'y']].values\n",
    "            vehicle_ids = snapshot['id'].values\n",
    "            velocities = snapshot['speed'].values\n",
    "            headings = snapshot['heading'].values\n",
    "            accelerations = snapshot['acceleration'].values\n",
    "            labels = snapshot['label'].values\n",
    "            kd_tree = KDTree(positions)\n",
    "            \n",
    "            for i, (vid, pos, vel, head,acceleration,label) in enumerate(zip(vehicle_ids, positions, velocities, headings,accelerations,labels)):\n",
    "                object_type = extract_object_type(vid)  # Extract object type from ID\n",
    "                acceleration = 0.0 if math.isnan(acceleration) else acceleration\n",
    "                # add self\n",
    "                cam = {\n",
    "                    'timestep': t,\n",
    "                    'cpm_id': f\"CPM_{vid}_{t}\",\n",
    "                    'vehicle_id': vid,\n",
    "                    'object_type': object_type,\n",
    "                    'cls':t_cls,\n",
    "                    'label': label , \n",
    "                    'x': pos[0] ,\n",
    "                    'y': pos[1] ,\n",
    "                    'speed': vel,\n",
    "                    'heading': head,\n",
    "                    'acceleration': acceleration,\n",
    "                    'is_self': 1\n",
    "                }\n",
    "                cpm_data.append(cam)\n",
    "                all_objects.append({\n",
    "                                'timestep': cam['timestep'],\n",
    "                                'cpm_id':   cam['cpm_id'],\n",
    "                                'vehicle_id': cam['vehicle_id'],\n",
    "                                'detected_vehicle_id': None,\n",
    "                                'object_type':  cam['object_type'],\n",
    "                                'detected_object_type':  None,\n",
    "                                'cls_detected': cam['cls'],\n",
    "                                'label_detected':  cam['label'],\n",
    "                                'x_detected': cam['x'],\n",
    "                                'y_detected': cam['y'],\n",
    "                                'speed_detected':  cam['speed'],\n",
    "                                'heading_detected':  cam['heading'],\n",
    "                                'acceleration_detected':  cam['acceleration'],\n",
    "                                'is_self':  cam['is_self'],\n",
    "                                'sensor_id': None,\n",
    "                                'sensor_type': None,\n",
    "                                'sensor_range': None,\n",
    "                                'weather_conditions': current_weather,\n",
    "                                'visibility_range': visibility_range,\n",
    "                                'detection_confidence': None\n",
    "                            })\n",
    "                for sensor in sensor_types:\n",
    "                    sensor_range = min(sensor_ranges[sensor], visibility_range)\n",
    "                    \n",
    "                    # Find nearest neighbors within sensor range\n",
    "                    indices = kd_tree.query_ball_point(pos, sensor_range)\n",
    "                    \n",
    "                    for idx in indices:\n",
    "                        if idx != i:  # Exclude self\n",
    "                            # Create CPM entry\n",
    "                            cpm = {\n",
    "                                'timestep': t,\n",
    "                                'cpm_id': f\"CPM_{vid}_{t}\",\n",
    "                                'vehicle_id': vid,\n",
    "                                'detected_vehicle_id': vehicle_ids[idx],\n",
    "                                'object_type': object_type,\n",
    "                                'detected_object_type': extract_object_type(vehicle_ids[idx]),\n",
    "                                'cls_detected':t_cls, #no noise? TODO:\n",
    "                                'label_detected': labels[idx] , #no noise? TODO:\n",
    "                                'x_detected': positions[idx][0] + np.random.normal(0, 1),  # Add noise\n",
    "                                'y_detected': positions[idx][1] + np.random.normal(0, 1),\n",
    "                                'speed_detected': velocities[idx] + np.random.normal(0, 0.5),\n",
    "                                'heading_detected': headings[idx] + np.random.normal(0, 1),\n",
    "                                'acceleration_detected': (0.0 if math.isnan(accelerations[idx]) else accelerations[idx]) + np.random.normal(0, 1),\n",
    "                                'is_self': 0,\n",
    "                                'sensor_id': f\"Sensor_{vid}_{sensor}\",\n",
    "                                'sensor_type': sensor,\n",
    "                                'sensor_range': sensor_range,\n",
    "                                'weather_conditions': current_weather,\n",
    "                                'visibility_range': visibility_range,\n",
    "                                'detection_confidence': np.random.uniform(0.6, 1.0),  # Varies with weather\n",
    "                            }\n",
    "                            detected_objects.append(cpm)\n",
    "                            all_objects.append(cpm)\n",
    "                    \n",
    "                # cpm_data.append(cam)\n",
    "        current_ts+=1\n",
    "\n",
    "    if cpm_data:\n",
    "        # Save enhanced dataset\n",
    "        save_ds(t, cpm_data,detected_objects,all_objects)\n",
    "        cpm_data = [] \n",
    "        detected_objects=[]\n",
    "        all_objects=[]\n",
    "    # return pd.DataFrame(cpm_data)\n",
    "\n",
    "# Generate CPM dataset\n",
    "generate_cpm(vehicles)\n",
    "\n",
    "# # Save enhanced dataset\n",
    "# cpm_dataset.to_csv(\"burst_adma_with_cpm_multi_sensors.csv\", index=False)\n",
    "# print(\"CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors.csv\")\n",
    "# import sqlite3\n",
    "# # Create your connection.\n",
    "# cnx = sqlite3.connect('imported_data/burst_adma_with_cpm_multi_sensors.db')\n",
    "# cpm_dataset.to_sql(name='burst_adma_with_cpm_multi_sensors', con=cnx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/burst_adma_with_clusters_in_time.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load BurST-ADMA dataset (Assuming CSV format)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/burst_adma_with_clusters_in_time.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update with actual path\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Extract relevant fields\u001b[39;00m\n\u001b[1;32m     12\u001b[0m vehicles \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestep\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheading\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egcnoi_env/lib/python3.10/site-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/burst_adma_with_clusters_in_time.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load BurST-ADMA dataset (Assuming CSV format)\n",
    "file_path = \"data/burst_adma_with_clusters_in_time.csv\"  # Update with actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant fields\n",
    "vehicles = data[['id', 'timestep', 'x', 'y', 'speed', 'heading','acceleration','label','cls']]\n",
    "\n",
    "# Define sensor range (meters)\n",
    "SENSOR_TYPES = [\"LiDAR\", \"Camera\", \"Radar\"]\n",
    "SENSOR_RANGES = {\"LiDAR\": 50, \"Camera\": 40, \"Radar\": 80}\n",
    "MAX_TS=1000\n",
    "FOLDER_TO_SAVE=f\"burst_adma_with_cpm_multi_sensors_cls_lidar_{SENSOR_RANGES['LiDAR']}\"\n",
    "# Function to extract object type from vehicle ID\n",
    "def extract_object_type(id):\n",
    "    if id.startswith('bike') :\n",
    "        return 'bicycle'\n",
    "    elif id.startswith('bus') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('moto') :\n",
    "        return 'motorcycle'\n",
    "    elif id.startswith('ped') :\n",
    "       return 'pedestrian'\n",
    "    elif id.startswith('pt_bus_') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('pt_tram_') :\n",
    "        return 'bus'\n",
    "    elif id.startswith('truck') :\n",
    "        return 'truck'\n",
    "    elif id.startswith('veh') :\n",
    "        return 'vehicle'\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "def save_ds(current_ts,all_objects):\n",
    "    # Save cam+cpm dataset\n",
    "    cpm_dataset=pd.DataFrame(all_objects)\n",
    "    cpm_dataset.to_csv(f\"{FOLDER_TO_SAVE}/burst_adma_with_cpm_multi_sensors{int(current_ts)}_cls_all.csv\", index=False)\n",
    "    cpm_dataset=None \n",
    "    print(f\"CPM-enhanced dataset with multiple sensors saved as burst_adma_with_cpm_multi_sensors{int(current_ts)}_cls.csv\")\n",
    "  \n",
    "\n",
    "# Function to simulate CPM detection with multiple sensors\n",
    "def generate_cpm(vehicles, sensor_types=SENSOR_TYPES, sensor_ranges=SENSOR_RANGES):\n",
    "    all_objects = []\n",
    "    timestamps = vehicles['timestep'].unique()\n",
    "    \n",
    "    # Simulate environmental conditions\n",
    "    weather_conditions = np.random.choice(['clear', 'foggy', 'rainy', 'snowy'], size=len(timestamps))\n",
    "    visibility_ranges = {\n",
    "        'clear': 100,\n",
    "        'foggy': 30,\n",
    "        'rainy': 50,\n",
    "        'snowy': 40,\n",
    "        #TODO'sun':?\n",
    "    }\n",
    "    current_ts=0\n",
    "    for idx, t in tqdm(enumerate(timestamps)):\n",
    "        if all_objects and current_ts % MAX_TS==0:\n",
    "            # Save enhanced dataset\n",
    "            save_ds(t,  all_objects) \n",
    "            all_objects=[]\n",
    "\n",
    "            \n",
    "        current_weather = weather_conditions[idx]\n",
    "        visibility_range = visibility_ranges[current_weather]\n",
    "\n",
    "        clasess = vehicles['cls'].unique()\n",
    "        snapshot_v = vehicles[vehicles['timestep'] == t]\n",
    "        for idx_cls, t_cls in enumerate(clasess):\n",
    "            snapshot = snapshot_v[snapshot_v['cls'] == t_cls]\n",
    "            positions = snapshot[['x', 'y']].values\n",
    "            vehicle_ids = snapshot['id'].values\n",
    "            velocities = snapshot['speed'].values\n",
    "            headings = snapshot['heading'].values\n",
    "            accelerations = snapshot['acceleration'].values\n",
    "            labels = snapshot['label'].values\n",
    "            kd_tree = KDTree(positions)\n",
    "            \n",
    "            for i, (vid, pos, vel, head,acceleration,label) in enumerate(zip(vehicle_ids, positions, velocities, headings,accelerations,labels)):\n",
    "                object_type = extract_object_type(vid)  # Extract object type from ID\n",
    "                acceleration = 0.0 if math.isnan(acceleration) else acceleration\n",
    "                # add self\n",
    "                cam = {\n",
    "                    'timestep': t,\n",
    "                    'cpm_id': f\"CPM_{vid}_{t}\",\n",
    "                    'vehicle_id': vid,\n",
    "                    'object_type': object_type,\n",
    "                    'cls':t_cls,\n",
    "                    'label': label , \n",
    "                    'x': pos[0] ,\n",
    "                    'y': pos[1] ,\n",
    "                    'speed': vel,\n",
    "                    'heading': head,\n",
    "                    'acceleration': acceleration,\n",
    "                    'is_self': 1\n",
    "                } \n",
    "                all_objects.append({\n",
    "                                'timestep': cam['timestep'],\n",
    "                                'cpm_id':   cam['cpm_id'],\n",
    "                                'vehicle_id': cam['vehicle_id'],\n",
    "                                'detected_vehicle_id': '',\n",
    "                                'object_type':  cam['object_type'],\n",
    "                                'detected_object_type':  '',\n",
    "                                'cls_detected': cam['cls'],\n",
    "                                'label_detected':  cam['label'],\n",
    "                                'x_detected': cam['x'],\n",
    "                                'y_detected': cam['y'],\n",
    "                                'speed_detected':  cam['speed'],\n",
    "                                'heading_detected':  cam['heading'],\n",
    "                                'acceleration_detected':  cam['acceleration'],\n",
    "                                'is_self':  cam['is_self'],\n",
    "                                'sensor_id': '',\n",
    "                                'sensor_type': '',\n",
    "                                'sensor_range': '0',\n",
    "                                'weather_conditions': current_weather,\n",
    "                                'visibility_range': visibility_range,\n",
    "                                'detection_confidence': '0'\n",
    "                            })\n",
    "                for sensor in sensor_types:\n",
    "                    sensor_range = min(sensor_ranges[sensor], visibility_range)\n",
    "                    \n",
    "                    # Find nearest neighbors within sensor range\n",
    "                    indices = kd_tree.query_ball_point(pos, sensor_range)\n",
    "                    \n",
    "                    for idx in indices:\n",
    "                        if idx != i:  # Exclude self\n",
    "                            # Create CPM entry\n",
    "                            cpm = {\n",
    "                                'timestep': t,\n",
    "                                'cpm_id': f\"CPM_{vid}_{t}\",\n",
    "                                'vehicle_id': vid,\n",
    "                                'detected_vehicle_id': vehicle_ids[idx],\n",
    "                                'object_type': object_type,\n",
    "                                'detected_object_type': extract_object_type(vehicle_ids[idx]),\n",
    "                                'cls_detected':t_cls, #no noise? TODO:\n",
    "                                'label_detected': labels[idx] , #no noise? TODO:\n",
    "                                'x_detected': positions[idx][0] + np.random.normal(0, 1),  # Add noise\n",
    "                                'y_detected': positions[idx][1] + np.random.normal(0, 1),\n",
    "                                'speed_detected': velocities[idx] + np.random.normal(0, 0.5),\n",
    "                                'heading_detected': headings[idx] + np.random.normal(0, 1),\n",
    "                                'acceleration_detected': (0.0 if math.isnan(accelerations[idx]) else accelerations[idx]) + np.random.normal(0, 1),\n",
    "                                'is_self': 0,\n",
    "                                'sensor_id': f\"Sensor_{vid}_{sensor}\",\n",
    "                                'sensor_type': sensor,\n",
    "                                'sensor_range': sensor_range,\n",
    "                                'weather_conditions': current_weather,\n",
    "                                'visibility_range': visibility_range,\n",
    "                                'detection_confidence': np.random.uniform(0.6, 1.0),  # Varies with weather\n",
    "                            } \n",
    "                            all_objects.append(cpm)\n",
    "                     \n",
    "        current_ts+=1\n",
    "\n",
    "    if all_objects:\n",
    "        # Save enhanced dataset\n",
    "        save_ds(t,  all_objects) \n",
    "        all_objects=[] \n",
    "\n",
    "# Generate CPM dataset\n",
    "generate_cpm(vehicles)\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egcnoi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
